{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:41.530884Z",
     "start_time": "2025-10-14T15:42:41.520929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Finding Derivative by using Function\n",
    "# def dy_dx(x1):\n",
    "#     return 2*x1\n",
    "# dy_dx(3)\n"
   ],
   "id": "e3b3e08c1f092b7e",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T11:39:53.274214Z",
     "start_time": "2025-10-15T11:39:46.840235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Auto_grad is a core components of pytorch that provides automatic differential for Tensors\n",
    "#requires_grad is By default is False ,if we want to perform gradient to the Tensor we have to set requires_grad=True\n",
    "#Note:Autograd is only performs on float and complex number of Tensors only\n",
    "import torch\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "x=torch.tensor(3.0,requires_grad=True)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:40:17.150410Z",
     "start_time": "2025-10-15T11:40:17.131937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y=x**2\n",
    "#Output:This Output will specifies How derivative will performs to the given Tensor\n",
    "# tensor(9., grad_fn=<PowBackward0>)\n",
    "\n",
    "y.backward()\n",
    "x.grad"
   ],
   "id": "42678ff683d2d72d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:41.967699Z",
     "start_time": "2025-10-14T15:42:41.948748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Using Two values of the Derivative\n",
    "# import math\n",
    "# def dz_dx(x1):\n",
    "#     return 2*x1*math.cos(x1**2)\n",
    "# dz_dx(3)\n",
    "import torch\n",
    "x=torch.tensor(3.0,requires_grad=True)\n",
    "y=x**2\n",
    "z=torch.sin(y)\n",
    "z.backward()\n",
    "x.grad"
   ],
   "id": "180600a1384b9078",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:46:31.246890Z",
     "start_time": "2025-10-15T11:46:31.235445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Finding Whether The student Got placed at campus drive based on there CGPA\n",
    "import torch\n",
    "#inputs\n",
    "x=torch.tensor(6.7)#Input Feature\n",
    "y=torch.tensor(0.0)#True Label(Binary)\n",
    "\n",
    "w=torch.tensor(1.0)#Weight\n",
    "b=torch.tensor(0.0)#Bias\n",
    "\n"
   ],
   "id": "915b28776be43e82",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:44:03.584565Z",
     "start_time": "2025-10-15T11:44:03.570924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Binaryclass Entropy Loss for Scalar\n",
    "def Binary_cross_Entropy(prediction,Target):\n",
    "    epsilon=1e-8 #To prevent Log(0)\n",
    "    prediction=torch.clamp(prediction,epsilon,1-epsilon)\n",
    "    return -(Target*torch.log(prediction)+(1-Target)*torch.log(1-prediction))"
   ],
   "id": "6b1391acf3ca5039",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:44:05.502341Z",
     "start_time": "2025-10-15T11:44:05.484005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Forward Pass\n",
    "z=w*x+b #Weighted sum (Linear Part)\n",
    "y_preds=torch.sigmoid(z)\n",
    "y_preds"
   ],
   "id": "4e70696478cf16d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:44:08.170464Z",
     "start_time": "2025-10-15T11:44:08.152529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Computing the Binary cross Entropy Loss\n",
    "Loss=Binary_cross_Entropy(y_preds,y)\n",
    "Loss\n"
   ],
   "id": "7d8ddf2e384bdff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:44:11.577641Z",
     "start_time": "2025-10-15T11:44:11.560962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Derivatives\n",
    "#1.dL/d(y_preds):Loss with respect to prediction (y_preds)\n",
    "dLoss_dy_Preds=(y_preds-y)/(y_preds*(1-y_preds))\n",
    "#2.dy_pred/dz:prediction (y_pred) with respect to z (sigmoid)\n",
    "dy_Preds_dz=y_preds*(1-y_preds)\n",
    "#3.dz/dw and dz/db :z with respect to w and b\n",
    "dz_dw=x\n",
    "dz_db=1\n",
    "dL_dw=dLoss_dy_Preds*dy_Preds_dz*dz_dw\n",
    "dL_db=dLoss_dy_Preds*dy_Preds_dz*dz_db"
   ],
   "id": "86eeadb0465afc2d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:44:14.228016Z",
     "start_time": "2025-10-15T11:44:14.214329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'The Manual Gradient of the Loss w.r.t to weights is {dL_dw}')\n",
    "print(f'The Manual Gradient of the Loss w.r.t to Bias is {dL_db}')\n"
   ],
   "id": "849beb57358d8c7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manual Gradient of the Loss w.r.t to weights is 6.691762447357178\n",
      "The Manual Gradient of the Loss w.r.t to Bias is 0.998770534992218\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using Backward",
   "id": "ca7e0afd242ed6d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:43.405843Z",
     "start_time": "2025-10-14T15:42:43.395895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.tensor(6.7)\n",
    "y=torch.tensor(0.0)"
   ],
   "id": "4bf943f34264de6",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:43.550122Z",
     "start_time": "2025-10-14T15:42:43.528627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w=torch.tensor(1.0,requires_grad=True)\n",
    "b=torch.tensor(0.0,requires_grad=True)"
   ],
   "id": "21bc4f1f3f5cc23a",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:43.705762Z",
     "start_time": "2025-10-14T15:42:43.688800Z"
    }
   },
   "cell_type": "code",
   "source": "w",
   "id": "c6f45aa449371fe6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:43.923525Z",
     "start_time": "2025-10-14T15:42:43.908096Z"
    }
   },
   "cell_type": "code",
   "source": "b",
   "id": "4258c41c6f40d1ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:44.186802Z",
     "start_time": "2025-10-14T15:42:44.168513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Forward Propagation\n",
    "z=w*x+b\n",
    "z"
   ],
   "id": "b8c0447880a68f2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:44.400366Z",
     "start_time": "2025-10-14T15:42:44.382641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred=torch.sigmoid(z)\n",
    "y_pred"
   ],
   "id": "fe58e2c4e5bf0b9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:44.683283Z",
     "start_time": "2025-10-14T15:42:44.666963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss=Binary_cross_Entropy(y_pred,y)\n",
    "loss"
   ],
   "id": "c0e8f5e64021c536",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:44.885592Z",
     "start_time": "2025-10-14T15:42:44.875054Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "id": "b61be95051a8605e",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:44.960676Z",
     "start_time": "2025-10-14T15:42:44.950456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{w.grad}\")\n",
    "print(f\"{b.grad}\")"
   ],
   "id": "1a6fcd489bac6222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6917619705200195\n",
      "0.9987704753875732\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.135123Z",
     "start_time": "2025-10-14T15:42:45.118334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.tensor([1.0,2.0,3.0],requires_grad=True)\n",
    "x"
   ],
   "id": "7fbad8597f338978",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.405696Z",
     "start_time": "2025-10-14T15:42:45.390696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y=(x**2).mean()\n",
    "y"
   ],
   "id": "ecf697eabf35ebd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.580450Z",
     "start_time": "2025-10-14T15:42:45.572140Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "4ad0d4be555fcace",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.652906Z",
     "start_time": "2025-10-14T15:42:45.635789Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad",
   "id": "8d5c14b2ecf6ca40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clearing Gradient",
   "id": "dafd0c2a7078a955"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.887516Z",
     "start_time": "2025-10-14T15:42:45.876201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "a=torch.tensor(2.0,requires_grad=True)"
   ],
   "id": "6cc74e0401c43294",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:45.993272Z",
     "start_time": "2025-10-14T15:42:45.974315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Forward pass\n",
    "b=a**2\n",
    "b"
   ],
   "id": "24fec2b09497fac6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:46.251829Z",
     "start_time": "2025-10-14T15:42:46.241735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Backward Pass\n",
    "b.backward()"
   ],
   "id": "e1b364003dc70adf",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:46.384876Z",
     "start_time": "2025-10-14T15:42:46.365246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#a.grad will accumulate the all gradient in it,if run 2nd time the new gradient is added to the previous stored gradient\n",
    "a.grad"
   ],
   "id": "e7af7d1088210f25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:46.671930Z",
     "start_time": "2025-10-14T15:42:46.655522Z"
    }
   },
   "cell_type": "code",
   "source": "a.grad.zero_()",
   "id": "caf8fbf233934403",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Disable the gradient Tracking",
   "id": "d7f35b542abd5bbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:46.924614Z",
     "start_time": "2025-10-14T15:42:46.906004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.tensor(2.0,requires_grad=True)\n",
    "x"
   ],
   "id": "7ecef72e44c024fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:47.198632Z",
     "start_time": "2025-10-14T15:42:47.184700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y=x**2\n",
    "y"
   ],
   "id": "3dd24e5cfb42a65f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:47.448849Z",
     "start_time": "2025-10-14T15:42:47.430474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y.backward()\n",
    "x.grad\n"
   ],
   "id": "f0ab665784d70de0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Option1-requires_grad_(False)<br>\n",
    "Option2-detach()<br>\n",
    "Option3-torch.no_grad()"
   ],
   "id": "33b7de4dfe3ff13f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:47.676922Z",
     "start_time": "2025-10-14T15:42:47.661132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x.requires_grad_(False)\n",
    "#in output attribute require_grad=True is Not There\n",
    "x\n",
    "#This will Give the Error\n",
    "# y.backward()"
   ],
   "id": "7526e8120f14a9cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:47.884660Z",
     "start_time": "2025-10-14T15:42:47.870672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Option2:detach() we use this function to create the new Tensor ,that should have the requires_grad is equal to False\n",
    "x=torch.tensor(2.0,requires_grad=True)\n",
    "print(\"The Tensor which has requires_grad=True\",x)\n",
    "z=x.detach()\n",
    "print(f\"The Tensor Created by detach() function which has doesn't have the requires_grad=True and only has Tensor {z}\")"
   ],
   "id": "c5c301fc2cf0d5fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tensor which has requires_grad=True tensor(2., requires_grad=True)\n",
      "The Tensor Created by detach() function which has doesn't have the requires_grad=True and only has Tensor 2.0\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:48.094961Z",
     "start_time": "2025-10-14T15:42:48.075829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Here the gradient is work on x Tensor\n",
    "y=x**2\n",
    "y"
   ],
   "id": "83dda10f8d961cf5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:48.310151Z",
     "start_time": "2025-10-14T15:42:48.293893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#But to z Tensor the Gradient is Not Work\n",
    "y1=z**2\n",
    "y1"
   ],
   "id": "9884cdc1a9255344",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:48.509836Z",
     "start_time": "2025-10-14T15:42:48.490792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Work properly\n",
    "y.backward()\n",
    "#Produce Error\n",
    "# y1.backward()\n",
    "x.grad"
   ],
   "id": "6af33cd3969c1321",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:48.732187Z",
     "start_time": "2025-10-14T15:42:48.714756Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad.zero_()",
   "id": "e15b139066c8ad23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:48.975969Z",
     "start_time": "2025-10-14T15:42:48.958785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Option3:torch.no_grad():\n",
    "x=torch.tensor(2.0,requires_grad=True)\n",
    "x"
   ],
   "id": "1e95ea6668404d65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:49.230499Z",
     "start_time": "2025-10-14T15:42:49.214264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    y=x**2\n",
    "    #y.backward() gives Error\n",
    "y"
   ],
   "id": "a7d1c761c74b65a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T15:42:49.617307Z",
     "start_time": "2025-10-14T15:42:49.590880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#performing autograd on Vectors And Matrix\n",
    "import torch\n",
    "x=torch.tensor([1,2,3,4.],requires_grad=True)\n",
    "a=torch.tensor([[1,2,3.],\n",
    "                [4,5,6.]],requires_grad=True)\n",
    "y=x**2+3*x\n",
    "b=a**3+5*a\n",
    "y.sum().backward()\n",
    "b.sum().backward()\n",
    "print(\"The Gradient of the x Tensor is \",x.grad)\n",
    "print(\"The Gradient of the a Tensor is \",a.grad)"
   ],
   "id": "db873f6994836383",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient of the x Tensor is  tensor([ 5.,  7.,  9., 11.])\n",
      "The Gradient of the a Tensor is  tensor([[  8.,  17.,  32.],\n",
      "        [ 53.,  80., 113.]])\n"
     ]
    }
   ],
   "execution_count": 138
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
