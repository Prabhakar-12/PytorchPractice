{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:28:29.446755Z",
     "start_time": "2025-10-13T17:28:29.425621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Finding Derivative by using Function\n",
    "# def dy_dx(x1):\n",
    "#     return 2*x1\n",
    "# dy_dx(3)\n"
   ],
   "id": "e3b3e08c1f092b7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T17:30:19.201959Z",
     "start_time": "2025-10-13T17:30:19.192903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Auto_grad is a core components of pytorch that provides automatic differential for Tensors\n",
    "#requires_grad is By default is False ,if we want to perform gradient to the Tensor we have to set requires_grad=True\n",
    "import torch\n",
    "x=torch.tensor(3.0,requires_grad=True)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:28:35.464584Z",
     "start_time": "2025-10-13T17:28:35.446742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y=x**2\n",
    "y\n",
    "#Output:This Output will specifies How derivative will performs to the given Tensor\n",
    "# tensor(9., grad_fn=<PowBackward0>)\n",
    "\n",
    "y.backward()\n",
    "x.grad"
   ],
   "id": "42678ff683d2d72d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:44:34.240146Z",
     "start_time": "2025-10-13T17:44:34.222518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Using Two values of the Derivative\n",
    "# import math\n",
    "# def dz_dx(x1):\n",
    "#     return 2*x1*math.cos(x1**2)\n",
    "# dz_dx(3)\n",
    "import torch\n",
    "x=torch.tensor(3.0,requires_grad=True)\n",
    "y=x**2\n",
    "z=torch.sin(y)\n",
    "z.backward()\n",
    "x.grad"
   ],
   "id": "180600a1384b9078",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:51:26.221322Z",
     "start_time": "2025-10-13T17:51:26.210160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Finding Whether The student Got placed at campus drive based on there CGPA\n",
    "import torch\n",
    "#inputs\n",
    "x=torch.tensor(6.7)#Input Feature\n",
    "y=torch.tensor(0.0)#True Label(Binary)\n",
    "\n",
    "w=torch.tensor(1.0)#Weight\n",
    "b=torch.tensor(0.0)#Bias\n",
    "\n"
   ],
   "id": "915b28776be43e82",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:51:27.902099Z",
     "start_time": "2025-10-13T17:51:27.891146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Binaryclass Entropy for Loss for Scalar\n",
    "def Binary_cross_Entropy(prediction,Target):\n",
    "    epsilon=1e-8 #To prevent Log(0)\n",
    "    prediction=torch.clamp(prediction,epsilon,1-epsilon)\n",
    "    return -(Target*torch.log(prediction)+(1-Target)*torch.log(1-prediction))"
   ],
   "id": "6b1391acf3ca5039",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:51:54.528932Z",
     "start_time": "2025-10-13T17:51:54.508550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Forward Pass\n",
    "z=w*x+b #Weighted sum (Linear Part)\n",
    "y_preds=torch.sigmoid(z)\n",
    "y_preds"
   ],
   "id": "4e70696478cf16d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:52:56.877711Z",
     "start_time": "2025-10-13T17:52:56.860368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Computing the Binary cross Entropy Loss\n",
    "Loss=Binary_cross_Entropy(y_preds,y)\n",
    "Loss\n"
   ],
   "id": "7d8ddf2e384bdff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T18:00:41.535941Z",
     "start_time": "2025-10-13T18:00:41.520815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Derivatives\n",
    "#1.dL/d(y_preds):Loss with respect to prediction (y_preds)\n",
    "dLoss_dy_Preds=(y_preds-y)/(y_preds*(1-y_preds))\n",
    "#2.dy_pred/dz:prediction (y_pred) with respect to z (sigmoid)\n",
    "dy_Preds_dz=y_preds*(1-y_preds)\n",
    "#3.dz/dw and dz/db :z with respect to w and b\n",
    "dz_dw=x\n",
    "dz_db=1\n",
    "dL_dw=dLoss_dy_Preds*dy_Preds_dz*dz_dw\n",
    "dL_db=dLoss_dy_Preds*dy_Preds_dz*dz_db"
   ],
   "id": "86eeadb0465afc2d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T18:01:43.285025Z",
     "start_time": "2025-10-13T18:01:43.272663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'The Manual Gradient of the Loss w.r.t to weights is {dL_dw}')\n",
    "print(f'The Manual Gradient of the Loss w.r.t to Bias is {dL_db}')"
   ],
   "id": "849beb57358d8c7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manual Gradient of the Loss w.r.t to weights is 6.691762447357178\n",
      "The Manual Gradient of the Loss w.r.t to Bias is 0.998770534992218\n"
     ]
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
